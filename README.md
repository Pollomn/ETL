# ğŸ›’ Dropshipping Pipeline

Un pipeline ETL complet pour un site de dropshipping vÃªtements, utilisant Kafka/Redpanda pour le streaming, Snowflake pour le stockage et l'analyse, et Streamlit pour le monitoring en temps rÃ©el.

## ğŸ—ï¸ Architecture

```
Data Generator â†’ CSV Export â†’ Kafka Producer â†’ Redpanda â†’ Consumer â†’ Snowflake RAW â†’ Stream â†’ Task â†’ PROD â†’ Streamlit Dashboard
```

### Composants

- **GÃ©nÃ©ration de donnÃ©es** : Scripts Python pour crÃ©er des donnÃ©es rÃ©alistes (clients, produits, commandes)
- **Streaming** : Redpanda (Kafka-compatible) pour la gestion des Ã©vÃ©nements en temps rÃ©el
- **Stockage** : Snowflake avec schÃ©mas RAW, STAGING, PROD
- **ETL automatisÃ©** : Streams et Tasks Snowflake pour l'ingestion automatique
- **Monitoring** : Dashboard Streamlit avec KPIs et visualisations

## ğŸš€ Installation rapide

### PrÃ©requis

- Python 3.11+
- Docker & Docker Compose
- SnowSQL (pour Snowflake)
- uv (gestionnaire de dÃ©pendances Python)

### Installation

```bash
# 1. Cloner le repo
git clone <repo-url>
cd dropshipping-pipeline

# 2. Installer les dÃ©pendances
make install

# 3. Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos credentials Snowflake

# 4. Setup complet
make all
```

## ğŸ“‹ Workflow d'exÃ©cution

### 1. GÃ©nÃ©ration des donnÃ©es

```bash
# GÃ©nÃ©rer les donnÃ©es de test
make generate-data

# Ou avec paramÃ¨tres personnalisÃ©s
python scripts/export_seed.py --customers 1000 --products 200 --orders 5000 --seed 42
```

### 2. Infrastructure Kafka

```bash
# DÃ©marrer Redpanda
make docker-up

# VÃ©rifier que Kafka est disponible
docker ps
```

### 3. Configuration Snowflake

```bash
# ExÃ©cuter les scripts SQL
bash snowflake/run_all.sh
```

### 4. Pipeline de streaming

```bash
# Terminal 1: Producer (mode replay)
python scripts/producer.py --mode replay --rate 10

# Terminal 2: Consumer
python scripts/consumer_snowflake.py

# Terminal 3: Validation
python scripts/validate.py
```

### 5. Monitoring

```bash
# Dashboard Streamlit
make monitor
# Ou directement: streamlit run streamlit_monitor/app.py
```

## ğŸ”§ Configuration

### Variables d'environnement (.env)

```bash
# Snowflake
SNOW_ACCOUNT=your_account
SNOW_USER=your_user
SNOW_PASSWORD=your_password
SNOW_ROLE=ACCOUNTADMIN
SNOW_WAREHOUSE=COMPUTE_WH
SNOW_DATABASE=DROPSHIPPING_DB
SNOW_SCHEMA=RAW

# Kafka
KAFKA_BOOTSTRAP_SERVERS=localhost:9092
KAFKA_TOPIC=orders_topic
```

### Structure des donnÃ©es

#### Clients (customers.csv)
- `customer_id`, `name`, `email`, `city`, `channel`

#### Produits (inventory.csv)
- `product_id`, `product_name`, `category`, `unit_price`, `stock_quantity`

#### Commandes (orders.csv)
- `id`, `product_id`, `customer_id`, `quantity`, `unit_price`, `sold_at`

## ğŸ“Š Monitoring et validation

### Dashboard Streamlit

Le dashboard affiche :
- **KPIs** : Total commandes, CA, clients uniques, produits uniques
- **Top produits** : Par volume et chiffre d'affaires
- **Commandes rÃ©centes** : 20 derniÃ¨res commandes
- **Tendances** : Graphiques des commandes et revenus quotidiens

### Validation automatique

```bash
# VÃ©rifier la qualitÃ© des donnÃ©es
make validate

# Le script gÃ©nÃ¨re un rapport JSON dans reports/
```

## ğŸ§ª Tests rapides

### VÃ©rifier Kafka

```bash
# Lister les topics
docker exec -it redpanda rpk topic list

# Consommer les messages
docker exec -it redpanda rpk topic consume orders_topic
```

### VÃ©rifier Snowflake

```sql
-- Compter les Ã©vÃ©nements
SELECT COUNT(*) FROM raw.orders_events;

-- Compter les commandes
SELECT COUNT(*) FROM prod.orders;

-- VÃ©rifier la task
SHOW TASKS IN SCHEMA prod;
```

## ğŸ“ Structure du projet

```
/
â”œâ”€â”€ data/seed/                    # CSV exportÃ©s
â”œâ”€â”€ docker/                       # Configuration Docker
â”œâ”€â”€ scripts/                      # Scripts Python
â”‚   â”œâ”€â”€ export_seed.py           # GÃ©nÃ©ration donnÃ©es
â”‚   â”œâ”€â”€ producer.py              # Producer Kafka
â”‚   â”œâ”€â”€ consumer_snowflake.py    # Consumer Snowflake
â”‚   â””â”€â”€ validate.py              # Validation qualitÃ©
â”œâ”€â”€ snowflake/                    # Scripts SQL
â”‚   â”œâ”€â”€ 01_create_warehouse_db_schemas.sql
â”‚   â”œâ”€â”€ 02_create_tables.sql
â”‚   â”œâ”€â”€ 03_create_stream_and_task.sql
â”‚   â”œâ”€â”€ 04_validate_ingestion.sql
â”‚   â””â”€â”€ run_all.sh               # ExÃ©cution sÃ©quentielle
â”œâ”€â”€ streamlit_monitor/            # Dashboard
â”œâ”€â”€ reports/                      # Rapports validation
â”œâ”€â”€ docs/                         # Documentation
â””â”€â”€ .env.example                  # Template configuration
```

## ğŸš¨ DÃ©pannage

### Erreur de connexion Snowflake
- VÃ©rifier les credentials dans `.env`
- Tester la connexion : `snowsql -a $SNOW_ACCOUNT -u $SNOW_USER`

### Kafka non accessible
- VÃ©rifier que Redpanda est dÃ©marrÃ© : `docker ps`
- Tester la connexion : `docker exec -it redpanda rpk cluster health`

### DonnÃ©es manquantes
- VÃ©rifier que les scripts SQL ont Ã©tÃ© exÃ©cutÃ©s
- VÃ©rifier que le consumer fonctionne
- VÃ©rifier que la task Snowflake est active

## ğŸ“ˆ Performance

### Recommandations

- **Warehouse Snowflake** : XSMALL pour le dÃ©veloppement, SMALL+ pour la production
- **Rate limiting** : Ajuster `--rate` selon la capacitÃ© de traitement
- **Batch size** : Modifier la taille des batches dans le consumer

### Monitoring

- **Snowsight** : Interface web Snowflake pour les requÃªtes
- **Streamlit** : Dashboard temps rÃ©el
- **Logs** : VÃ©rifier les logs des scripts pour les erreurs

## ğŸ”„ Modes de fonctionnement

### Mode Replay
```bash
python scripts/producer.py --mode replay --file data/seed/orders.csv --rate 10
```
Rejoue les commandes depuis un fichier CSV Ã  un rythme configurable.

### Mode Stream
```bash
python scripts/producer.py --mode stream --rate 5
```
GÃ©nÃ¨re continuellement de nouvelles commandes alÃ©atoires.

## ğŸ“ Logs et rapports

- **Logs** : AffichÃ©s dans la console des scripts
- **Rapports** : `reports/validate_report_TIMESTAMP.json`
- **Dashboard** : Interface web Streamlit

## ğŸ¤ Contribution

1. Fork le projet
2. CrÃ©er une branche feature
3. Commit les changements
4. Push vers la branche
5. Ouvrir une Pull Request

## ğŸ“„ Licence

MIT License - voir [LICENSE](LICENSE) pour plus de dÃ©tails.

## ğŸ†˜ Support

Pour toute question ou problÃ¨me :
1. VÃ©rifier la documentation
2. Consulter les logs d'erreur
3. Tester les composants individuellement
4. Ouvrir une issue sur GitHub
