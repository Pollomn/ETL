# ğŸ“¸ Checklist pour Captures et VidÃ©o

Ce document fournit les instructions dÃ©taillÃ©es pour gÃ©nÃ©rer les preuves de fonctionnement du pipeline.

## ğŸ¯ Objectifs des captures

1. **Snowsight** : Montrer les donnÃ©es dans Snowflake (raw vs prod)
2. **VidÃ©o** : DÃ©monstration complÃ¨te du pipeline en action
3. **Dashboard** : Interface Streamlit fonctionnelle

## ğŸ“‹ Checklist de prÃ©paration

### Avant de commencer

- [ ] Pipeline complÃ¨tement configurÃ© et testÃ©
- [ ] DonnÃ©es gÃ©nÃ©rÃ©es (`make generate-data`)
- [ ] Snowflake configurÃ© (`bash snowflake/run_all.sh`)
- [ ] Redpanda dÃ©marrÃ© (`make docker-up`)
- [ ] Tous les scripts fonctionnels

### VÃ©rifications prÃ©alables

```bash
# 1. VÃ©rifier que les donnÃ©es sont gÃ©nÃ©rÃ©es
ls -la data/seed/
# Doit contenir: customers.csv, inventory.csv, orders.csv

# 2. VÃ©rifier que Redpanda fonctionne
docker ps
# Doit voir le conteneur redpanda

# 3. VÃ©rifier la connexion Snowflake
snowsql -a $SNOW_ACCOUNT -u $SNOW_USER -q "SELECT 1;"
```

## ğŸ“¸ Captures Snowsight

### Capture 1 : DonnÃ©es RAW

1. Ouvrir Snowsight
2. ExÃ©cuter la requÃªte :
   ```sql
   SELECT COUNT(*) as raw_events_count FROM raw.orders_events;
   ```
3. Capturer l'Ã©cran montrant le rÃ©sultat

### Capture 2 : DonnÃ©es PROD

1. Dans Snowsight, exÃ©cuter :
   ```sql
   SELECT COUNT(*) as prod_orders_count FROM prod.orders;
   ```
2. Capturer l'Ã©cran montrant le rÃ©sultat

### Capture 3 : Comparaison

1. ExÃ©cuter la requÃªte de validation :
   ```sql
   SELECT 
       'Raw Events' as table_name,
       COUNT(*) as record_count
   FROM raw.orders_events
   UNION ALL
   SELECT 
       'Production Orders' as table_name,
       COUNT(*) as record_count
   FROM prod.orders;
   ```
2. Capturer l'Ã©cran avec les deux compteurs

## ğŸ¥ Enregistrement vidÃ©o (60 secondes)

### Timeline recommandÃ©e

**0-10s : DÃ©marrage du producer**
- Ouvrir terminal
- Lancer : `python scripts/producer.py --mode replay --rate 10`
- Montrer les logs de dÃ©marrage

**10-20s : Consumer en action**
- Ouvrir second terminal
- Lancer : `python scripts/consumer_snowflake.py`
- Montrer les logs d'insertion

**20-35s : Snowsight en temps rÃ©el**
- Ouvrir Snowsight
- ExÃ©cuter : `SELECT COUNT(*) FROM raw.orders_events;`
- RafraÃ®chir plusieurs fois pour montrer l'augmentation
- ExÃ©cuter : `SELECT COUNT(*) FROM prod.orders;`

**35-50s : Task Snowflake**
- Dans Snowsight, exÃ©cuter :
  ```sql
  ALTER TASK prod.ingest_orders_task EXECUTE;
  ```
- Attendre quelques secondes
- VÃ©rifier que prod.orders s'incrÃ©mente

**50-60s : Dashboard Streamlit**
- Ouvrir : `streamlit run streamlit_monitor/app.py`
- Montrer les KPIs et graphiques

### Commandes d'enregistrement

#### Option 1 : macOS (QuickTime + ffmpeg)

```bash
# Enregistrement Ã©cran avec QuickTime
# 1. Ouvrir QuickTime Player
# 2. Fichier > Nouvel enregistrement d'Ã©cran
# 3. SÃ©lectionner la zone d'Ã©cran
# 4. Enregistrer pendant 60 secondes

# Conversion avec ffmpeg (optionnel)
ffmpeg -i screen_recording.mov -t 60 -c:v libx264 -crf 23 demo.mp4
```

#### Option 2 : OBS Studio (Cross-platform)

1. **Configuration OBS** :
   - CrÃ©er une scÃ¨ne "Pipeline Demo"
   - Ajouter source "Capture d'Ã©cran"
   - RÃ©solution : 1920x1080

2. **Enregistrement** :
   - Bouton "DÃ©marrer l'enregistrement"
   - DurÃ©e : 60 secondes
   - Format : MP4

3. **Post-traitement** :
   ```bash
   # Compression (optionnel)
   ffmpeg -i obs_recording.mp4 -c:v libx264 -crf 23 -preset fast demo.mp4
   ```

#### Option 3 : ffmpeg direct (macOS)

```bash
# Enregistrement direct avec ffmpeg
ffmpeg -f avfoundation -i "1:0" -t 60 -r 30 -c:v libx264 -crf 23 demo.mp4

# Explication des paramÃ¨tres :
# -f avfoundation : Utilise AVFoundation (macOS)
# -i "1:0" : Ã‰cran 1, audio 0
# -t 60 : DurÃ©e 60 secondes
# -r 30 : 30 FPS
# -c:v libx264 : Codec vidÃ©o
# -crf 23 : QualitÃ© (18-28, plus bas = meilleure qualitÃ©)
```

## ğŸ§ª Tests de validation

### Test 1 : Pipeline complet

```bash
# 1. Nettoyer l'environnement
make clean
make docker-down

# 2. Setup complet
make all

# 3. Configurer Snowflake
bash snowflake/run_all.sh

# 4. Test end-to-end
python scripts/producer.py --mode replay --rate 10 &
PRODUCER_PID=$!

python scripts/consumer_snowflake.py &
CONSUMER_PID=$!

# Attendre 30 secondes
sleep 30

# ArrÃªter les processus
kill $PRODUCER_PID $CONSUMER_PID

# 5. Validation
python scripts/validate.py

# 6. Dashboard
streamlit run streamlit_monitor/app.py
```

### Test 2 : VÃ©rifications rapides

```bash
# VÃ©rifier Kafka
docker exec -it redpanda rpk topic list
docker exec -it redpanda rpk topic consume orders_topic --num 5

# VÃ©rifier Snowflake
snowsql -a $SNOW_ACCOUNT -u $SNOW_USER -q "SELECT COUNT(*) FROM raw.orders_events;"
snowsql -a $SNOW_ACCOUNT -u $SNOW_USER -q "SELECT COUNT(*) FROM prod.orders;"

# VÃ©rifier les fichiers
ls -la data/seed/
ls -la reports/
```

## ğŸ“Š MÃ©triques de succÃ¨s

### CritÃ¨res de validation

- [ ] **DonnÃ©es gÃ©nÃ©rÃ©es** : 1000 clients, 200 produits, 5000 commandes
- [ ] **Kafka fonctionnel** : Producer et consumer communiquent
- [ ] **Snowflake alimentÃ©** : raw.orders_events contient des donnÃ©es
- [ ] **ETL automatisÃ©** : prod.orders s'alimente via la task
- [ ] **Dashboard actif** : KPIs cohÃ©rents affichÃ©s
- [ ] **Validation passÃ©e** : Tous les checks de qualitÃ© OK

### Commandes de vÃ©rification

```bash
# 1. Compter les Ã©vÃ©nements Kafka
docker exec -it redpanda rpk topic consume orders_topic --num 100 | wc -l

# 2. Compter les donnÃ©es Snowflake
snowsql -a $SNOW_ACCOUNT -u $SNOW_USER -q "
SELECT 
    (SELECT COUNT(*) FROM raw.orders_events) as raw_count,
    (SELECT COUNT(*) FROM prod.orders) as prod_count;"

# 3. VÃ©rifier la task
snowsql -a $SNOW_ACCOUNT -u $SNOW_USER -q "
SELECT STATE, LAST_SCHEDULED_TIME, LAST_COMPLETED_TIME 
FROM TABLE(INFORMATION_SCHEMA.TASK_HISTORY()) 
WHERE TASK_NAME = 'INGEST_ORDERS_TASK' 
ORDER BY SCHEDULED_TIME DESC LIMIT 1;"
```

## ğŸ¬ Script de dÃ©monstration

### Script automatisÃ© pour la vidÃ©o

```bash
#!/bin/bash
# demo_script.sh - Script automatisÃ© pour la dÃ©monstration

echo "ğŸ¬ DÃ©marrage de la dÃ©monstration..."

# 1. Nettoyer et prÃ©parer
make clean
make docker-down
sleep 2

# 2. Setup
echo "ğŸ“¦ Setup de l'environnement..."
make all
sleep 5

# 3. Snowflake
echo "â„ï¸ Configuration Snowflake..."
bash snowflake/run_all.sh
sleep 3

# 4. DÃ©marrer le pipeline
echo "ğŸš€ DÃ©marrage du pipeline..."
python scripts/producer.py --mode replay --rate 10 &
PRODUCER_PID=$!

python scripts/consumer_snowflake.py &
CONSUMER_PID=$!

# 5. Attendre l'ingestion
echo "â³ Attente de l'ingestion (30s)..."
sleep 30

# 6. Validation
echo "âœ… Validation..."
python scripts/validate.py

# 7. Dashboard
echo "ğŸ“Š DÃ©marrage du dashboard..."
streamlit run streamlit_monitor/app.py &
DASHBOARD_PID=$!

# 8. Nettoyage aprÃ¨s dÃ©mo
echo "ğŸ§¹ Nettoyage..."
sleep 10
kill $PRODUCER_PID $CONSUMER_PID $DASHBOARD_PID 2>/dev/null
make docker-down

echo "ğŸ‰ DÃ©monstration terminÃ©e!"
```

## ğŸ“ Notes finales

- **DurÃ©e vidÃ©o** : 60 secondes maximum
- **QualitÃ©** : 1080p minimum
- **Audio** : Optionnel, mais recommandÃ© pour les explications
- **Format** : MP4 prÃ©fÃ©rÃ©
- **Taille** : < 100MB pour faciliter le partage

### Checklist finale

- [ ] VidÃ©o enregistrÃ©e (60s)
- [ ] Captures Snowsight
- [ ] Dashboard fonctionnel
- [ ] Validation passÃ©e
- [ ] Documentation complÃ¨te
- [ ] Repo prÃªt pour livraison
